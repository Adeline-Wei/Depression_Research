{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import RegPattern\n",
    "import re\n",
    "import math\n",
    "import codecs\n",
    "from nltk.corpus import stopwords\n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokens(str1): \n",
    "\t#stop_words = set(stopwords.words('english'))\n",
    "\tstop_words = []\n",
    "\tresult = []\n",
    "\tfor i in str1.strip().split(' '):\n",
    "\t\t# print( i )\n",
    "\t\tif i not in stop_words:\n",
    "\t\t\tresult.append(i)\n",
    "\tif result == []:\n",
    "\t\tresult = ['']\n",
    "\treturn result\n",
    "\n",
    "# to remove url\n",
    "def del_url(line): #return re.sub(r'https?:\\/\\/.*', \"\", line).lower()\n",
    "\tresult = ''\n",
    "\t# p_list = [\"s'\",\"'s\"]\n",
    "\tfor i in re.sub(r'https?:\\/\\/.*', \"\", line).lower().split(' '):\n",
    "\t\tif \"s'\" in i:\n",
    "\t\t\tresult += i.replace(\"s'\",\" \")\n",
    "\t\telif \"'s\" in i:\n",
    "\t\t\tresult += i.replace(\"'s\",\" \")\n",
    "\t\telif i.startswith(\"'\"):\n",
    "\t\t\tresult += i.replace(\"'\",\" \") + \" \"\n",
    "\t\telif i.endswith(\"'\"):\n",
    "\t\t\tresult += i.replace(\"'\",\" \")\n",
    "\t\telse:\n",
    "\t\t\tresult += i + \" \"\n",
    "            \n",
    "\treturn result\n",
    "\n",
    "# print( (tokens(del_url(\"\"))) )\n",
    "\n",
    "def checktag(tweet):\n",
    "\ttimes = 0\n",
    "\temp_result = ''\n",
    "\tresult = ''\n",
    "\tfor i in tweet.split(' '):\n",
    "\t\tif i.startswith('#'): #remove @ amd # (# result += '<HASHTAG>' + ' ' + i.replace('#',''))\n",
    "\t\t\t# result += '<HASHTAG>'\n",
    "\t\t\tresult += '<HASHTAG>' + ' ' + i.replace('#','')\n",
    "\t\t\tresult += ' '\n",
    "\t\t\ttimes += 1\n",
    "\t\telif i.startswith('@'):\n",
    "\t\t\tresult += '<user_name>'\n",
    "\t\t\tresult += ' '\n",
    "\t\telif 'pm' in i:\n",
    "\t\t\tresult += i.replace('pm',' <PM>')#change the time format and add 'space' to be tokenized\n",
    "\t\t\tresult += ' '\n",
    "\t\telse:\n",
    "\t\t\tresult += i\n",
    "\t\t\tresult += ' '\n",
    "\tif times >= 4:\n",
    "\t\treturn emp_result\n",
    "\treturn result\n",
    "\n",
    "def removeRT(tweet): #if RT: then discard this tweet\n",
    "\tresult = ''\n",
    "\tfor i in tweet.split(' '):\n",
    "\t\tif i.startswith('rt') or i.startswith('RT'): #remove @ amd #\n",
    "\t\t\tbreak\n",
    "\t\telse:\n",
    "\t\t\tresult += i\n",
    "\t\t\tresult += ' '\n",
    "\treturn result\n",
    "\n",
    "reg = RegPattern.RegPattern()\n",
    "\n",
    "def regTime(tweet):\n",
    "\tfinalResult1 = ''\n",
    "\tresult = (reg.get_pattern(tweet,'re_time'))\n",
    "\t# print( reg.re_time )\n",
    "\t# print( result )\n",
    "\tfor i in result:\n",
    "\t\tfinalResult1 += str(i) + ' '\n",
    "\treturn finalResult1\n",
    "\n",
    "def regPatterns(tweet):\n",
    "\tfinalResult = ''\n",
    "\tresult = (reg.get_pattern(tweet,'re_all'))\n",
    "\t# print( result )\n",
    "\tfor i in result:\n",
    "\t\tfinalResult += i + ' '\n",
    "\treturn finalResult \n",
    "\n",
    "def sample_match(emoPath, meta):\n",
    "\tedges = {}\n",
    "# \tprint( \"Processing \"+emoPath )\n",
    "\n",
    "\tcontent_file = codecs.open(emoPath,\"r\",encoding='utf-8')\n",
    "\tout = codecs.open(\"./network/samples_\"+meta,\"w\", \"utf-8-sig\")\n",
    "\t#emoji = load_list(\"./emo_list.txt\",\"./XD_list.txt\")#\n",
    "\tword_list = []\n",
    "\tfor line in content_file:\n",
    "\t\tline = line.strip()\n",
    "\t\tfor word in tokens(regPatterns(checktag(del_url(line)))):\n",
    "\t\t\tword_list.append(word)\n",
    "\t\t\tout.write(word)\n",
    "\t\t\tout.write(\"\\n\")\n",
    "\tif meta == \"2\":\n",
    "\t\treturn word_list\n",
    "\t\n",
    "\tchbigram=list2bigram(word_list)\n",
    "\tbigramfreqdict=bigram2freqdict(chbigram)\n",
    "\tbigramfreqsorted=sorted(bigramfreqdict.items(), key=itemgetter(1), reverse=True)\n",
    "\t#print( bigramfreqsorted )\n",
    "\n",
    "\tmaxi = 0.0\n",
    "\tfoundMax = 0\n",
    "\tfor (token,num) in bigramfreqsorted:\n",
    "\t\tif len(token[0]) != 0 and len(token[1]) != 0:\n",
    "\t\t\tw1 = token[0]\n",
    "\t\t\tw2 = token[1]\n",
    "\t\t\tif not foundMax:\n",
    "\t\t\t\tfoundMax = 1\n",
    "\t\t\t\tmaxi = float(num)\n",
    "\t\t\t#out.write(\"%s -> %s : %d - %f\"%(token[0],token[1],num, float(num)/float(maxi)))\n",
    "\t\t\t#out.write(\"\\n\")\n",
    "\t\t\tedges[\"%s\\t%s\"%(w1,w2)]=float(num)/float(maxi)\n",
    "\tout.close()\n",
    "\treturn edges;\n",
    "\n",
    "def pattern_match(line):\n",
    "\tword_list = []\n",
    "\tline = line.strip()\n",
    "\tfor word in tokens(regPatterns(checktag(del_url(line)))):\n",
    "\t\tword_list.append(word)\n",
    "\treturn word_list\n",
    "\n",
    "\n",
    "def list2freqdict(mylist):\n",
    "\tmydict=dict()\n",
    "\tfor ch in mylist:\n",
    "\t\tmydict[ch]=mydict.get(ch,0)+1\n",
    "\treturn mydict\n",
    "\n",
    "def list2bigram(mylist):\n",
    "\treturn [mylist[i:i+2] for i in range(0,len(mylist)-1)]\n",
    "\n",
    "def bigram2freqdict(mybigram):\n",
    "\tmydict=dict()\n",
    "\tfor (ch1,ch2) in mybigram:\n",
    "\t\tmydict[(ch1,ch2)]=mydict.get((ch1,ch2),0)+1\n",
    "\treturn mydict\n",
    "\n",
    "def replace_space(path):\n",
    "\twith codecs.open(path,\"r\", \"utf-8\") as content_file:\n",
    "\t\tcontent = content_file.read()\n",
    "# \tprint( content )\n",
    "\tcontent.replace(\" \",\"_blank_\")\n",
    "\tout = codecs.open(\"path\",\"w\", \"utf-8-sig\")\n",
    "\tout.write(content)\n",
    "\tout.close()\n",
    "\n",
    "#sample_match(\"./network/test_data3/accurate.txt\",\"test\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
