{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, math\n",
    "import operator\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "from random import randint\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import TweetTokenizer\n",
    "import sys, os\n",
    "global stop_words\n",
    "stop_words = stopwords.words('english')\n",
    "import datetime\n",
    "from matplotlib import dates\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn')\n",
    "import matplotlib.dates as mdates\n",
    "from ipywidgets import IntProgress\n",
    "from IPython.display import display\n",
    "import string\n",
    "sys.path.append('../English_to_IPA/src/')\n",
    "import conversion as cv\n",
    "sys.path.append('../age_gender_predictor/')\n",
    "import predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Patient(object):\n",
    "    totalCount = 0\n",
    "    \n",
    "    def __init__(self, userId):\n",
    "        self.userId = userId\n",
    "        self.df = pd.read_csv('../0_dataset/DepressionUsersTweets/Patch0_data_PoL/'+userId,sep='\\t',header=None,usecols=[0,1,2,3,4,5,6,7],names=['Date','Id','Name','Text','Senti','Emo1','Emo2','Ambiguos'],quoting=3,error_bad_lines=False,encoding='utf-8').dropna(axis=0, how='any')\n",
    "        self.df = self.df.drop_duplicates(subset='Date', keep='first')\n",
    "        self.df = self.df.set_index('Date')\n",
    "        self.df.index = pd.to_datetime(self.df.index)\n",
    "        \n",
    "        Patient.totalCount += 1 \n",
    "        \n",
    "    def displayCount(self):\n",
    "        print(\"Total Patients {0}\".format(Patient.totalCount))\n",
    "    \n",
    "    def displayTweetsCount(self):\n",
    "        return len(self.df)\n",
    "        \n",
    "    def getText(self):\n",
    "        return self.df['Text'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Ordinary(object):\n",
    "    totalCount = 0\n",
    "    \n",
    "       \n",
    "    def __init__(self, userId):\n",
    "        self.userId = userId\n",
    "        self.df = pd.read_csv('../0_dataset/OrdinaryUsersTweets_PoL/'+userId,sep='\\t',header=None,usecols=[0,1,2,3,4,5,6,7],names=['Date','Id','Name','Text','Senti','Emo1','Emo2','Ambiguos'],quoting=3,error_bad_lines=False,encoding='utf-8').dropna(axis=0, how='any')\n",
    "        self.df = self.df.drop_duplicates(subset='Date', keep='first')\n",
    "        self.df = self.df.set_index('Date')\n",
    "        self.df.index = pd.to_datetime(self.df.index)\n",
    "        self.df = self.df.sort_index(ascending=False)\n",
    "        \n",
    "        Patient.totalCount += 1 \n",
    "        \n",
    "    def displayCount(self):\n",
    "        print(\"Total Patients {0}\".format(Patient.totalCount))\n",
    "    \n",
    "    def displayTweetsCount(self):\n",
    "        return len(self.df)\n",
    "       \n",
    "        \n",
    "    def getText(self):\n",
    "        return self.df['Text'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def findUserIdFromDataset(group, num):\n",
    "    userIds = []\n",
    "    print(group+str(num))\n",
    "    with open('../0_dataset/' + group + 'Dataset' + str(num)) as open_file:\n",
    "        for line in open_file.readlines():\n",
    "            userIds.append(line.strip().split('\\t')[0])\n",
    "            \n",
    "    return userIds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readID(filename):\n",
    "    ids = []\n",
    "    with open(filename) as openFile:\n",
    "        for line in openFile.readlines():\n",
    "            ids.append(line.strip())\n",
    "            \n",
    "    return ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    textList = re.findall('(?u)\\\\b[a-zA-Z]\\\\w{0,}\\\\b', text)\n",
    "    return textList\n",
    "\n",
    "def replace_by_symbols(txt):\n",
    "    txt = re.sub(r\"https\\S+\", '', txt)\n",
    "    txt = re.sub(r\"http\\S+\", '', txt)\n",
    "    txt = re.sub(r\"pic.twitter.com\\S+\", '', txt)\n",
    "    txt = re.sub(r\"twitter.com/\\S+\", '', txt)\n",
    "    txt = re.sub(r\"\\S+/\\S+\", '', txt)\n",
    "    txt = re.sub(r\"@\\S+\", '', txt)\n",
    "    txt = re.sub(r\"#\\S+\", '', txt)\n",
    "    txt = re.sub(r\"idk\", 'i do not know', txt)   # idk: i don't know\n",
    "    txt = re.sub(r\"tbh\", 'to be honest', txt)   # tbh: to be honest\n",
    "    txt = re.sub(r\"tho\", 'though', txt)   # tho\n",
    "    txt = re.sub(r\"i\\'m\", 'i am', txt)\n",
    "    txt = re.sub(r\"you\\'re\", 'you are', txt)\n",
    "    txt = re.sub(r\"he\\'s\", 'he is', txt)\n",
    "    txt = re.sub(r\"she\\'s\", 'she is', txt)\n",
    "    txt = re.sub(r\"it\\'s\", 'it is', txt)\n",
    "    txt = re.sub(r\"we\\'re\", 'we are', txt)\n",
    "    txt = re.sub(r\"they\\'re\", 'they are', txt)\n",
    "    txt = re.sub(r\"isn\\'t\", 'is not', txt)\n",
    "    txt = re.sub(r\"don\\'t\", 'do not', txt)\n",
    "    txt = re.sub(r\"doesn\\'t\", 'does not', txt)\n",
    "    txt = re.sub(r\"didn\\'t\", 'did not', txt)\n",
    "    txt = re.sub(r\"wasn\\'t\", 'was not', txt)\n",
    "    txt = re.sub(r\"weren\\'t\", 'were not', txt)\n",
    "    txt = re.sub(r\"haven\\'t\", 'have not', txt)\n",
    "    txt = re.sub(r\"can\\'t\", 'can not', txt)\n",
    "    txt = re.sub(r\"couldn\\'t\", 'could not', txt)\n",
    "    txt = re.sub(r\"wouldn\\'t\", 'would not', txt)\n",
    "    txt = re.sub(r\"shouldn\\'t\", 'should not', txt)\n",
    "    txt = re.sub(r\"&amp\", '', txt)\n",
    "    return txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read UserID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "GD1, GD2, GD3 = ([] for i in range(3))\n",
    "BD1, BD2, BD3 = ([] for i in range(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "GD1 = readID('../0_dataset/patientDataset1ID')\n",
    "GD2 = readID('../0_dataset/patientDataset2ID')\n",
    "GD3 = readID('../0_dataset/patientDataset3ID')\n",
    "BD1 = readID('../0_dataset/ordinaryDataset1ID')\n",
    "BD2 = readID('../0_dataset/ordinaryDataset2ID')\n",
    "BD3 = readID('../0_dataset/ordinaryDataset3ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.92 s, sys: 28 ms, total: 2.95 s\n",
      "Wall time: 3.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "patientsD1 = dict()\n",
    "patientsD2 = dict()\n",
    "patientsD3 = dict()\n",
    "\n",
    "for ele in GD1:\n",
    "    patientsD1[ele] = Patient(ele)\n",
    "for ele in GD2:\n",
    "    patientsD2[ele] = Patient(ele)\n",
    "for ele in GD3:\n",
    "    patientsD3[ele] = Patient(ele)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.93 s, sys: 16 ms, total: 1.94 s\n",
      "Wall time: 2.81 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ordinarysD1 = dict()\n",
    "ordinarysD2 = dict()\n",
    "ordinarysD3 = dict()\n",
    "\n",
    "for ele in BD1:\n",
    "    ordinarysD1[ele] = Ordinary(ele)\n",
    "for ele in BD2:\n",
    "    ordinarysD2[ele] = Ordinary(ele)\n",
    "for ele in BD3:\n",
    "    ordinarysD3[ele] = Ordinary(ele)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *** eSPE V2 ***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eSPEDictV2 = dict()\n",
    "with open('eSPEPhonologicalTableV2') as openFile:\n",
    "    for line in openFile.readlines():\n",
    "        line = line.strip().split('\\t')\n",
    "        eSPEDictV2[line[0]] = np.array([eval(x) for x in line[1:]])\n",
    "        \n",
    "def getTweetScoreV2(tweet):\n",
    "    wordCount = 0\n",
    "    words = tokenize(tweet)\n",
    "    score = np.zeros((8,), dtype=np.int)\n",
    "    for word in words:\n",
    "        # 字典裡找不到這個字\n",
    "        cmu, ipa = cv.convert(word)\n",
    "        ipa = re.sub('[ˌˈ ]' ,'' ,ipa)\n",
    "        if '*' in ipa:\n",
    "            continue\n",
    "        wordCount += 1\n",
    "        i = 0\n",
    "        while i < len(ipa):\n",
    "            # 最後一個音標\n",
    "            if i == len(ipa)-1:\n",
    "                sym = ipa[i]\n",
    "                score += eSPEDictV2[sym]\n",
    "                i += 1\n",
    "            # 非最後一個音標\n",
    "            else:\n",
    "                try:\n",
    "                    sym = ipa[i] + ipa[i+1]\n",
    "                    score += eSPEDictV2[sym]\n",
    "                    i += 2\n",
    "                except KeyError:\n",
    "                    sym = ipa[i]\n",
    "                    score += eSPEDictV2[sym]\n",
    "                    i += 1\n",
    "\n",
    "    score = np.append(score, wordCount)\n",
    "    return score\n",
    "\n",
    "# Input:  該群人的文字\n",
    "# Return: 該群人的聲音分數\n",
    "def getPhonologicalScores(groupText):\n",
    "    groupScoresV2 = []\n",
    "    for i, person in enumerate(groupText):\n",
    "        tweets = person.split('\\n')\n",
    "        score = np.zeros((9,), dtype=np.int)\n",
    "        for tweet in tweets:\n",
    "            score += getTweetScoreV2(tweet)\n",
    "        groupScoresV2.append(list(score))\n",
    "    \n",
    "    return groupScoresV2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *** Pattern of Life ***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweetTknzr = TweetTokenizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Daily Tweet Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getTweetRate(df):\n",
    "    totalTweets = len(df)\n",
    "    delta_time = np.max(df.index.values) - np.min(df.index.values)\n",
    "    totla_duration = (delta_time).astype('timedelta64[h]') / np.timedelta64(24, 'h')\n",
    "    \n",
    "    return totalTweets / float(totla_duration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mention Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def thirdPronuonDetect(words, matcher=re.compile(\"@[a-z]+\")):\n",
    "    for word in words:\n",
    "        if word == \"@\":\n",
    "            continue\n",
    "        elif matcher.search(word):\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getMentionRate(df):\n",
    "    ''' 發文提到別人的比例 '''\n",
    "    \n",
    "    totalTweets = len(df)\n",
    "    total_mentions = 0\n",
    "    for item in df.iterrows():\n",
    "        if thirdPronuonDetect(tweetTknzr.tokenize(item[1]['Text'])):\n",
    "            total_mentions += 1\n",
    "\n",
    "    return total_mentions/float(totalTweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Frequent Mentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getFrequentMetions(df, lowerbound=3):\n",
    "    friends_mentions = {}\n",
    "    for item in df.iterrows():\n",
    "        for word in tweetTknzr.tokenize(item[1]['Text']):\n",
    "            if word[0] == '@' and len(word) > 1:\n",
    "                friends_mentions[word] = friends_mentions.get(word, 0) +1\n",
    "    frequent_frients = [screen_name for screen_name, mentions in friends_mentions.items() if mentions >= lowerbound]\n",
    "\n",
    "    return len(frequent_frients)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unique Mentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getUniqueMentions(df):\n",
    "    totalTweets = len(df)\n",
    "    friends_set = set()\n",
    "    for item in df.iterrows():\n",
    "        for word in tweetTknzr.tokenize(item[1]['Text']):\n",
    "            if word[0] == '@' and len(word) > 1:\n",
    "                friends_set.add(word)\n",
    "                \n",
    "    return len(friends_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gender / Age Query Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getAge(df):\n",
    "    # This function returns a float, representing the age. \n",
    "    texts = \"\"\n",
    "    for item in df.iterrows():\n",
    "        texts += item[1]['Text'] + \"\\n\"\n",
    "    return predictor.get_age(texts)\n",
    "\n",
    "def getGender(df):\n",
    "    # This function returns a float. Positive valuse represents female and vice versa.\n",
    "    texts = \"\"\n",
    "    for text in df.iterrows():\n",
    "        texts += item[1]['Text'] + \"\\n\"\n",
    "    return predictor.get_gender(texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Emotion Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getEmotionsDict(df):\n",
    "    user = df['Id'][0]\n",
    "    tweetsCount = 0\n",
    "    emotionDict = {\"joy\":0,\"sadness\": 0,\"fear\":0,\"anticipation\": 0,\"anger\":0,\"trust\": 0,\"disgust\": 0,\"surprise\" : 0}\n",
    "    for item in df.iterrows():\n",
    "        if item[1]['Ambiguos'] != 'yes':\n",
    "            tweetsCount += 1\n",
    "            emotion = item[1]['Emo1']\n",
    "            emotionDict[emotion] += 1\n",
    "    \n",
    "    for emotion in emotionDict:\n",
    "            if tweetsCount == 0:\n",
    "                emotionDict[emotion] = 0\n",
    "            else:\n",
    "                emotionDict[emotion] = float(emotionDict[emotion]) / tweetsCount\n",
    "    \n",
    "    return emotionDict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Positive / Negative Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getNegativeRatio(df):\n",
    "    totalTweets = len(df)\n",
    "    return sum(df.Senti == -1) / float(totalTweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getPositiveRatio(df):\n",
    "    totalTweets = len(df)\n",
    "    return sum(df.Senti == 1) / float(totalTweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Pattern of Life"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPatternOfLifeFeatures(df):\n",
    "    score = np.zeros((17,), dtype=np.float)\n",
    "    score[0] = round(getTweetRate(df), 2)\n",
    "    score[1] = round(getMentionRate(df), 2)\n",
    "    score[2] = getFrequentMetions(df)\n",
    "    score[3] = getUniqueMentions(df)\n",
    "    score[4] = round(getAge(df), 1)\n",
    "    if getGender(df) >= 0:\n",
    "        score[5] = 1\n",
    "    else:\n",
    "        score[6] = 0\n",
    "    \n",
    "    emotionsDict = getEmotionsDict(df)\n",
    "    score[7] = round(emotionsDict[\"joy\"], 2)\n",
    "    score[8] = round(emotionsDict[\"sadness\"], 2)\n",
    "    score[9] = round(emotionsDict[\"fear\"], 2)\n",
    "    score[10] = round(emotionsDict[\"anticipation\"], 2)\n",
    "    score[11] = round(emotionsDict[\"anger\"], 2)\n",
    "    score[12] = round(emotionsDict[\"trust\"], 2)\n",
    "    score[13] = round(emotionsDict[\"disgust\"], 2)\n",
    "    score[14] = round(emotionsDict[\"surprise\"], 2)\n",
    "    score[15] = round(getPositiveRatio(df), 2)\n",
    "    score[16] = round(getNegativeRatio(df), 2)\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Playgound Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = ordinarysD1['1007626946'].df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = getPatternOfLifeFeatures(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.0"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.5599999999999996"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *** Extracting Feature ***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "groupD1Text = []\n",
    "for patient in patientsD1:\n",
    "    groupD1Text.append(replace_by_symbols('\\n'.join(patientsD1[patient].getText())))\n",
    "groupD2Text = []\n",
    "for patient in patientsD2:\n",
    "    groupD2Text.append(replace_by_symbols('\\n'.join(patientsD2[patient].getText())))\n",
    "groupD3Text = []\n",
    "for patient in patientsD3:\n",
    "    groupD3Text.append(replace_by_symbols('\\n'.join(patientsD3[patient].getText())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "baseD1Text = []\n",
    "for ordinary in ordinarysD1:\n",
    "    baseD1Text.append(replace_by_symbols('\\n'.join(ordinarysD1[ordinary].getText())))\n",
    "baseD2Text = []\n",
    "for ordinary in ordinarysD2:\n",
    "    baseD2Text.append(replace_by_symbols('\\n'.join(ordinarysD2[ordinary].getText())))\n",
    "baseD3Text = []\n",
    "for ordinary in ordinarysD3:\n",
    "    baseD3Text.append(replace_by_symbols('\\n'.join(ordinarysD3[ordinary].getText())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ClassfierInfo(object):\n",
    "    classifierCounter = 0\n",
    "    \n",
    "    def __init__(self, name, cl, X, Y):\n",
    "        self.name = name\n",
    "        self.trainIndex = list()\n",
    "        self.testIndex = list()\n",
    "        self.precision = 0\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        self.classifier = cl\n",
    "        self.prediction, self.bias, self.contributions = ti.predict(cl, X)\n",
    "        ClassfierInfo.classifierCounter += 1\n",
    "        \n",
    "    def displayClassifierCount(self):\n",
    "        print(\"Total {0} classifiers\".format(ClassfierInfo.classifierCounter))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getRandomForestPrecision(baseFeatures, groupFeatures, storageName, fold=10):\n",
    "    X = np.array(baseFeatures + groupFeatures)\n",
    "    Y = np.array([0] * len(baseFeatures) + [1]*len(groupFeatures), dtype=int)\n",
    "    sss = StratifiedShuffleSplit(Y, fold, random_state=randint(0,65536))\n",
    "    classifier  = RandomForestClassifier(n_jobs=-1, max_features=\"sqrt\", n_estimators=128)\n",
    "\n",
    "    classifierStorage = [None]*(sss.n_iter)\n",
    "    i = 0\n",
    "    for train_index, test_index in sss:\n",
    "\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        Y_train, Y_test = Y[train_index], Y[test_index]\n",
    "        classifier = RandomForestClassifier(n_jobs=-1, max_features=\"sqrt\", n_estimators=128)\n",
    "        classifier.fit(X_train, Y_train)\n",
    "        precision = classifier.score(X_test, Y_test)\n",
    "\n",
    "        classifierStorage[i] = ClassfierInfo(storageName+\"-\"+str(i), classifier, X, Y)\n",
    "        classifierStorage[i].train_index = train_index\n",
    "        classifierStorage[i].test_index = test_index\n",
    "        classifierStorage[i].precision = precision\n",
    "        i += 1\n",
    "\n",
    "    avgPrecision = 0\n",
    "    print(\"Precision of {0}\".format(storageName))\n",
    "    print(\"-\"*30)\n",
    "    for i, cl in enumerate(classifierStorage):\n",
    "        print(\"{0}\\t{1}\".format(i, cl.precision))\n",
    "        avgPrecision += cl.precision\n",
    "    print(\"-\"*30)    \n",
    "    print(\"Avg. precision: {0}\".format(avgPrecision/fold))\n",
    "    \n",
    "    \n",
    "    return classifierStorage"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
